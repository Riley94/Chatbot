{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import random\n",
    "from spacy.training import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "import io\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        medication\n",
      "0    acetaminophen\n",
      "1        acyclovir\n",
      "2         Adderall\n",
      "3        albuterol\n",
      "4      alendronate\n",
      "..             ...\n",
      "375    Zithromycin\n",
      "376         Zoloft\n",
      "377       Zolpidem\n",
      "378        Zovirax\n",
      "379         Zyrtec\n",
      "\n",
      "[380 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# if csv exists, load it\n",
    "if os.path.exists('../clean_data/medications.csv'):\n",
    "    medications = pd.read_csv('../clean_data/medications.csv')\n",
    "# otherwise, scrape the data\n",
    "else:\n",
    "    url = \"https://healthy.kaiserpermanente.org/health-wellness/drug-encyclopedia.\"\n",
    "\n",
    "    medications = []\n",
    "\n",
    "    # iterate from 'a' to 'z'\n",
    "    for letter in range(97, 123):\n",
    "        url = url + chr(letter)\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        for li in soup.select(\".drug-column-4\"):\n",
    "            medications.append(li.text)\n",
    "        \n",
    "        url = \"https://healthy.kaiserpermanente.org/health-wellness/drug-encyclopedia.\"\n",
    "\n",
    "    # split by new line\n",
    "    medications = [medication.split('\\n') for medication in medications]\n",
    "    # flatten and remove empty strings\n",
    "    medications = [medication for sublist in medications for medication in sublist if medication != '']\n",
    "    medications = pd.DataFrame(medications, columns=['medication'])\n",
    "    medications.to_csv('../clean_data/medications.csv', index=False)\n",
    "\n",
    "\n",
    "print(medications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "380 medication names to randomize NER data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scope of the application\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "# Function to authenticate and create the service\n",
    "def create_service():\n",
    "    creds = None\n",
    "    # The file token.pickle stores the user's access and refresh tokens.\n",
    "    if os.path.exists('token.pickle'):\n",
    "        with open('token.pickle', 'rb') as token:\n",
    "            creds = pickle.load(token)\n",
    "    # If there are no (valid) credentials available, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for the next run\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(creds, token)\n",
    "    \n",
    "    service = build('drive', 'v3', credentials=creds)\n",
    "    return service\n",
    "\n",
    "# Function to list files in a given folder ID\n",
    "def list_files_in_folder(service, folder_id):\n",
    "    results = service.files().list(q=f\"'{folder_id}' in parents\", fields=\"nextPageToken, files(id, name)\").execute()\n",
    "    items = results.get('files', [])\n",
    "    return items\n",
    "\n",
    "# Function to download a file\n",
    "def download_or_export_file(service, file_id, file_name, mime_type):\n",
    "    try:\n",
    "        # Check if the file is a Google Doc by its MIME type\n",
    "        if mime_type.startswith('application/vnd.google-apps.'):\n",
    "            # Define export MIME type for Google Docs (e.g., 'application/pdf' for Google Docs)\n",
    "            if mime_type == 'application/vnd.google-apps.document':\n",
    "                export_mime_type = 'application/pdf'\n",
    "                file_name += '.pdf'  # Append appropriate file extension\n",
    "            elif mime_type == 'application/vnd.google-apps.spreadsheet':\n",
    "                export_mime_type = 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'\n",
    "                file_name += '.xlsx'  # Append appropriate file extension\n",
    "            elif mime_type == 'application/vnd.google-apps.presentation':\n",
    "                export_mime_type = 'application/vnd.openxmlformats-officedocument.presentationml.presentation'\n",
    "                file_name += '.pptx'  # Append appropriate file extension\n",
    "            else:\n",
    "                # Default to PDF for other Google Apps documents\n",
    "                export_mime_type = 'application/pdf'\n",
    "                file_name += '.pdf'\n",
    "            \n",
    "            request = service.files().export_media(fileId=file_id, mimeType=export_mime_type)\n",
    "        else:\n",
    "            # For binary files, use the get_media method\n",
    "            request = service.files().get_media(fileId=file_id)\n",
    "        \n",
    "        # Perform the download or export\n",
    "        fh = io.BytesIO()\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while not done:\n",
    "            status, done = downloader.next_chunk()\n",
    "            print(f\"Download {int(status.progress() * 100)}%.\")\n",
    "        \n",
    "        # Write the file's contents to a local file\n",
    "        with open(file_name, 'wb') as f:\n",
    "            f.write(fh.getbuffer())\n",
    "        print(f\"File '{file_name}' downloaded successfully.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "def find_folders_by_name(service, folder_name):\n",
    "    \"\"\"Find folders by name and return their IDs.\"\"\"\n",
    "    query = f\"mimeType='application/vnd.google-apps.folder' and name='{folder_name}'\"\n",
    "    response = service.files().list(q=query, spaces='drive', fields='files(id, name)').execute()\n",
    "    return response.get('files', [])\n",
    "\n",
    "def find_subfolder_id(service, parent_folder_id, subfolder_name):\n",
    "    \"\"\"Find a specific subfolder within a parent folder.\"\"\"\n",
    "    query = f\"'{parent_folder_id}' in parents and mimeType='application/vnd.google-apps.folder' and name='{subfolder_name}'\"\n",
    "    response = service.files().list(q=query, spaces='drive', fields='files(id, name)').execute()\n",
    "    files = response.get('files', [])\n",
    "    if files:\n",
    "        return files[0]['id']  # Return the ID of the first matching subfolder\n",
    "    return None\n",
    "\n",
    "def download_txt_files_from_folder(service, folder_id):\n",
    "    \"\"\"Download all .txt files from a specified folder.\"\"\"\n",
    "    query = f\"'{folder_id}' in parents and mimeType='text/plain'\"\n",
    "    response = service.files().list(q=query, spaces='drive', fields='files(id, name, mimeType)').execute()\n",
    "    files = response.get('files', [])\n",
    "    for file in files:\n",
    "        print(f\"Downloading/exporting {file['name']}...\")\n",
    "        download_or_export_file(service, file['id'], file['name'], file['mimeType'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toy diagnosis data. Might look into a better source, but this will work for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 diagnosis\n",
      "0                  Acute Myeloid Leukaemia\n",
      "1     Adrenocortical Carcinoma (Localised)\n",
      "2    Adrenocortical Carcinoma (Metastatic)\n",
      "3      Adrenocortical Carcinoma (Regional)\n",
      "4                             ALL (B Cell)\n",
      "..                                     ...\n",
      "629                           Typhus Fever\n",
      "630                           Valley Fever\n",
      "631                        West Nile Fever\n",
      "632                           Yellow Fever\n",
      "633                             Zika Fever\n",
      "\n",
      "[634 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# again, if csv exists, load it\n",
    "if os.path.exists('../clean_data/diagnoses.csv'):\n",
    "    diagnoses = pd.read_csv('../clean_data/diagnoses.csv')\n",
    "# otherwise, download it from Google Drive\n",
    "else:\n",
    "    service = create_service()  # Assume this is implemented as shown before\n",
    "    top_level_folder_names = ['Base-Game', 'Mod-Diagnoses']\n",
    "\n",
    "    for folder_name in top_level_folder_names:\n",
    "        folders = find_folders_by_name(service, folder_name)\n",
    "        for folder in folders:\n",
    "            dept_diagnoses_folder_id = find_subfolder_id(service, folder['id'], 'Dept-Diagnoses')\n",
    "            if dept_diagnoses_folder_id:\n",
    "                download_txt_files_from_folder(service, dept_diagnoses_folder_id)\n",
    "    \n",
    "    diagnoses = []\n",
    "    # loop through all files and extract the text following '##' (diagnosis names)\n",
    "    for file in os.listdir('../raw_data/diagnoses'):\n",
    "        with open(f'../raw_data/diagnoses/{file}', 'r') as f:\n",
    "            for line in f:\n",
    "                if '##' in line:\n",
    "                    diagnoses.append(line.split('##')[1].strip())\n",
    "    \n",
    "    diagnoses = pd.DataFrame(diagnoses, columns=['diagnosis']).to_csv('../clean_data/diagnoses.csv', index=False)\n",
    "\n",
    "print(diagnoses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "634 diagnoses to randomize NER training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some dosages are nonsensical, but will hopefully allow the model to generalize well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['375 mL every 18 hours', '485 L', '635 mL', '80 mg', '105 L', '250 mg every 13 hours', '360 mL', '10 mg', '5 mg', '770 g', '710 mL every 16 hours', '440 L', '205 mL', '840 mg', '210 mL', '815 mg every 0 hours', '645 mg', '920 L', '375 g', '675 g', '230 mg every 26 hours', '600 L', '330 L', '1000 g', '950 L', '45 L every 25 hours', '65 g', '730 mL', '265 mg', '860 g', '725 L every 28 hours', '115 g', '320 g', '250 g', '80 g', '510 mg every 9 hours', '180 mg', '910 g', '495 mL', '95 g', '45 g every 31 hours', '365 mL', '915 L', '330 g', '860 mg', '670 g every 7 hours', '600 L', '70 mL', '105 mL', '775 L', '285 g once daily', '950 L', '115 g', '985 g', '570 mL', '325 g every 24 hours', '30 mL', '340 L', '465 mL', '450 g', '275 mg every 11 hours', '410 g', '345 L', '525 mL', '75 mL', '950 mL every 39 hours', '670 g', '445 L', '160 mL', '355 mg', '700 mL every 17 hours', '225 L', '735 L', '545 g', '655 mg', '905 L every 36 hours', '255 g', '240 mL', '325 g', '455 mg', '975 L every 6 hours', '595 L', '685 mL', '505 g', '380 g', '580 g every 38 hours', '830 L', '330 mL', '885 mg', '160 g', '700 L every 29 hours', '320 L', '885 mL', '595 mL', '110 L', '755 mg every 38 hours', '535 mg', '910 mL', '900 mg', '490 g', '310 mg every 20 hours', '305 mL', '660 g', '405 L', '75 mL', '775 mg every 42 hours', '395 g', '300 L', '225 mg', '225 mg', '495 L every 44 hours', '210 mL', '740 g', '995 mg', '515 g', '895 L every 41 hours', '275 g', '715 mg', '730 g', '290 mL', '460 mg every 43 hours', '460 L', '645 mg', '355 L', '645 L', '935 mL every 44 hours', '460 L', '270 mg', '545 mL', '20 mg', '530 mL every 0 hours', '980 mg', '815 g', '1000 mL', '735 mL', '380 L every 23 hours', '325 mg', '225 L', '790 mL', '845 g', '10 mg every 16 hours', '295 mg', '750 L', '260 g', '60 L', '680 mL every 30 hours', '610 g', '510 L', '500 L', '360 g', '945 mL every 34 hours', '490 g', '685 mL', '890 g', '160 g', '940 L every 22 hours', '665 mg', '230 L', '455 g', '920 mg', '555 g every 10 hours', '815 mg', '495 g', '885 L', '825 mg', '600 mg every 9 hours', '165 L', '480 g', '115 L', '55 mg', '60 g every 38 hours', '990 L', '580 g', '80 L', '830 L', '690 mL every 37 hours', '800 mg', '430 mg', '25 mg', '870 g', '800 L every 34 hours', '380 mg', '460 L', '700 g', '640 g', '825 mg every 25 hours', '490 mL', '870 L', '930 mL', '305 g', '195 mg every 13 hours', '225 g', '170 mL', '180 mg', '505 L', '320 L every 5 hours', '825 g', '670 g', '795 mL', '645 mL', '250 L every 38 hours', '985 L', '210 L', '75 L', '830 mL', '300 g every 12 hours', '220 mL', '880 L', '175 g', '325 mL', '155 mg twice daily', '885 mg', '170 L', '395 mg', '365 L', '605 g every 12 hours', '475 mL', '855 g', '260 mg', '870 mg', '965 L every 6 hours', '705 g', '620 L', '770 g', '730 g', '765 mg every 31 hours', '555 g', '910 mL', '765 mL', '170 mL', '720 L every 12 hours', '100 L', '1000 mL', '605 mL', '690 mL', '425 mg every 2 hours', '950 g', '510 mL', '430 mL', '65 L', '945 g every 5 hours', '405 g', '125 g', '380 g', '910 g', '555 mL every 41 hours', '495 g', '885 L', '265 g', '245 g', '305 mL every 11 hours', '630 mL', '690 mL', '920 mg', '460 mg', '760 L every 4 hours', '705 mg', '160 L', '740 mg', '875 mL', '960 g as needed', '350 mg', '800 L', '880 mg', '365 mg', '925 L every 29 hours', '725 g', '270 g', '980 g', '475 L', '835 mg every 15 hours', '660 mL', '980 mg', '730 L', '140 L', '970 mg every 0 hours', '745 L', '695 mg', '470 mg', '230 mL', '125 mL every 41 hours', '505 mL', '505 mL', '265 L', '795 L', '855 mL every 11 hours', '410 L', '985 mL', '745 mg', '345 mL', '465 g every 45 hours', '485 g', '805 mL', '180 L', '460 g', '110 mg every 3 hours', '855 L', '525 g', '315 g', '795 L']\n"
     ]
    }
   ],
   "source": [
    "# randomly generate dosage data\n",
    "dosages = []\n",
    "units = ['mg', 'g', 'mL', 'L']\n",
    "concat_every = 5\n",
    "frequency = ['twice daily', 'once daily', 'as needed']\n",
    "\n",
    "for hour in range(48):\n",
    "    frequency.append(f'every {hour} hours')\n",
    "\n",
    "for i in range(300):\n",
    "    dosage = str(random.choice(range(5, 1001, 5))) + f' {random.choice(units)}'\n",
    "    if i % concat_every == 0:\n",
    "        dosage += ' ' + random.choice(frequency)\n",
    "    dosages.append(dosage)\n",
    "\n",
    "print(dosages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if csv exists, load it\n",
    "if os.path.exists('../clean_data/tests.csv'):\n",
    "    tests = pd.read_csv('../clean_data/tests.csv')\n",
    "# otherwise, scrape the data\n",
    "else:\n",
    "    url = \"https://medlineplus.gov/lab-tests/\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    tests = []\n",
    "    # select all uorderdered lists with class 'withident breaklist'\n",
    "    for item in soup.select(\".withident.breaklist\"):\n",
    "        tests.append(item.text)\n",
    "\n",
    "    tests = pd.DataFrame(tests, columns=['test'])\n",
    "    tests['test'] = tests['test'].str.split('\\n')\n",
    "    tests = tests.explode('test')\n",
    "    tests = tests[tests['test'] != '']\n",
    "    tests.to_csv('../clean_data/tests.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if csv exists, load it\n",
    "if os.path.exists('../clean_data/symptoms.csv'):\n",
    "    symptoms = pd.read_csv('../clean_data/symptoms.csv')\n",
    "else:\n",
    "    symptoms = []\n",
    "    pattern = r\"\\+\\s(.+?)\\s\\(\\d+% of cases \\| .+?\\)\"\n",
    "\n",
    "    # loop through all files and extract the text following '##' (diagnosis names)\n",
    "    for file in os.listdir('../raw_data/diagnoses'):\n",
    "        with open(f'../raw_data/diagnoses/{file}', 'r') as f:\n",
    "            for line in f:\n",
    "                match = re.search(pattern, line)\n",
    "                if match:\n",
    "                    symptoms.append(match.group(1))\n",
    "\n",
    "    symptoms = pd.DataFrame(symptoms, columns=['symptom'])\n",
    "    # make unique\n",
    "    symptoms = symptoms.drop_duplicates()\n",
    "    symptoms.to_csv('../clean_data/symptoms.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['January 01', 'January 02', 'January 03', 'January 04', 'January 05', 'January 06', 'January 07', 'January 08', 'January 09', 'January 10', 'January 11', 'January 12', 'January 13', 'January 14', 'January 15', 'January 16', 'January 17', 'January 18', 'January 19', 'January 20', 'January 21', 'January 22', 'January 23', 'January 24', 'January 25', 'January 26', 'January 27', 'January 28', 'February 01', 'February 02', 'February 03', 'February 04', 'February 05', 'February 06', 'February 07', 'February 08', 'February 09', 'February 10', 'February 11', 'February 12', 'February 13', 'February 14', 'February 15', 'February 16', 'February 17', 'February 18', 'February 19', 'February 20', 'February 21', 'February 22', 'February 23', 'February 24', 'February 25', 'February 26', 'February 27', 'February 28', 'March 01', 'March 02', 'March 03', 'March 04', 'March 05', 'March 06', 'March 07', 'March 08', 'March 09', 'March 10', 'March 11', 'March 12', 'March 13', 'March 14', 'March 15', 'March 16', 'March 17', 'March 18', 'March 19', 'March 20', 'March 21', 'March 22', 'March 23', 'March 24', 'March 25', 'March 26', 'March 27', 'March 28', 'April 01', 'April 02', 'April 03', 'April 04', 'April 05', 'April 06', 'April 07', 'April 08', 'April 09', 'April 10', 'April 11', 'April 12', 'April 13', 'April 14', 'April 15', 'April 16', 'April 17', 'April 18', 'April 19', 'April 20', 'April 21', 'April 22', 'April 23', 'April 24', 'April 25', 'April 26', 'April 27', 'April 28', 'May 01', 'May 02', 'May 03', 'May 04', 'May 05', 'May 06', 'May 07', 'May 08', 'May 09', 'May 10', 'May 11', 'May 12', 'May 13', 'May 14', 'May 15', 'May 16', 'May 17', 'May 18', 'May 19', 'May 20', 'May 21', 'May 22', 'May 23', 'May 24', 'May 25', 'May 26', 'May 27', 'May 28', 'June 01', 'June 02', 'June 03', 'June 04', 'June 05', 'June 06', 'June 07', 'June 08', 'June 09', 'June 10', 'June 11', 'June 12', 'June 13', 'June 14', 'June 15', 'June 16', 'June 17', 'June 18', 'June 19', 'June 20', 'June 21', 'June 22', 'June 23', 'June 24', 'June 25', 'June 26', 'June 27', 'June 28', 'July 01', 'July 02', 'July 03', 'July 04', 'July 05', 'July 06', 'July 07', 'July 08', 'July 09', 'July 10', 'July 11', 'July 12', 'July 13', 'July 14', 'July 15', 'July 16', 'July 17', 'July 18', 'July 19', 'July 20', 'July 21', 'July 22', 'July 23', 'July 24', 'July 25', 'July 26', 'July 27', 'July 28', 'August 01', 'August 02', 'August 03', 'August 04', 'August 05', 'August 06', 'August 07', 'August 08', 'August 09', 'August 10', 'August 11', 'August 12', 'August 13', 'August 14', 'August 15', 'August 16', 'August 17', 'August 18', 'August 19', 'August 20', 'August 21', 'August 22', 'August 23', 'August 24', 'August 25', 'August 26', 'August 27', 'August 28', 'September 01', 'September 02', 'September 03', 'September 04', 'September 05', 'September 06', 'September 07', 'September 08', 'September 09', 'September 10', 'September 11', 'September 12', 'September 13', 'September 14', 'September 15', 'September 16', 'September 17', 'September 18', 'September 19', 'September 20', 'September 21', 'September 22', 'September 23', 'September 24', 'September 25', 'September 26', 'September 27', 'September 28', 'October 01', 'October 02', 'October 03', 'October 04', 'October 05', 'October 06', 'October 07', 'October 08', 'October 09', 'October 10', 'October 11', 'October 12', 'October 13', 'October 14', 'October 15', 'October 16', 'October 17', 'October 18', 'October 19', 'October 20', 'October 21', 'October 22', 'October 23', 'October 24', 'October 25', 'October 26', 'October 27', 'October 28', 'November 01', 'November 02', 'November 03', 'November 04', 'November 05', 'November 06', 'November 07', 'November 08', 'November 09', 'November 10', 'November 11', 'November 12', 'November 13', 'November 14', 'November 15', 'November 16', 'November 17', 'November 18', 'November 19', 'November 20', 'November 21', 'November 22', 'November 23', 'November 24', 'November 25', 'November 26', 'November 27', 'November 28', 'December 01', 'December 02', 'December 03', 'December 04', 'December 05', 'December 06', 'December 07', 'December 08', 'December 09', 'December 10', 'December 11', 'December 12', 'December 13', 'December 14', 'December 15', 'December 16', 'December 17', 'December 18', 'December 19', 'December 20', 'December 21', 'December 22', 'December 23', 'December 24', 'December 25', 'December 26', 'December 27', 'December 28']\n"
     ]
    }
   ],
   "source": [
    "dates = []\n",
    "\n",
    "# generate dates in the format \"Month Day\"\n",
    "for i in range(1, 13):\n",
    "    for j in range(1, 29):\n",
    "        # year is arbitrary\n",
    "        date = datetime.date(2021, i, j)\n",
    "        full_date = f\"{date.strftime('%B')} {date.strftime('%d')}\"\n",
    "        dates.append(full_date)\n",
    "\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "# generate times in the format \"Hour AM/PM\"\n",
    "for i in range(1, 13):\n",
    "    for j in [\"AM\", \"PM\"]:\n",
    "        time = f\"{i} {j}\"\n",
    "        times.append(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Body parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard-coding for now. Will change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anatomies = [\"left femur\", \"right knee\", \"abdominal region\", \"left lung\", \"right lung\", \"left kidney\", \"right kidney\",\n",
    "             \"left eye\", \"right eye\", \"left ear\", \"right ear\", \"left hand\", \"right hand\", \"left foot\", \"right foot\",\n",
    "             \"left arm\", \"right arm\", \"left leg\", \"right leg\", \"left shoulder\", \"right shoulder\", \"left hip\", \"right hip\",\n",
    "             \"left elbow\", \"right elbow\", \"left wrist\", \"right wrist\", \"left ankle\", \"right ankle\", \"left toe\", \"right toe\",\n",
    "             \"left finger\", \"right finger\", \"left thumb\", \"right thumb\", \"left nostril\", \"right nostril\", \"left cheek\", \"right cheek\",\n",
    "             \"left temple\", \"right temple\", \"left jaw\", \"right jaw\", \"left chin\", \"right chin\", \"left neck\", \"right neck\", \"left collarbone\",\n",
    "             \"right collarbone\", \"left rib\", \"right rib\", \"left hip bone\", \"right hip bone\", \"left thigh\", \"right thigh\", \"left calf\",\n",
    "             \"right calf\", \"left shin\", \"right shin\", \"left heel\", \"right heel\", \"left sole\", \"right sole\", \"left toe\", \"right toe\",\n",
    "             \"left finger\", \"right finger\", \"left thumb\", \"right thumb\", \"left palm\", \"right palm\", \"left wrist\", \"right wrist\", \"left forearm\",\n",
    "             \"right forearm\", \"left bicep\", \"right bicep\", \"left tricep\", \"right tricep\", \"left shoulder\", \"right shoulder\", \"left chest\", \"right chest\",\n",
    "             \"left breast\", \"right breast\", \"left nipple\", \"right nipple\", \"left rib\", \"right rib\", \"left abdomen\", \"right abdomen\", \"left hip\",\n",
    "             \"right hip\", \"left groin\", \"right groin\", \"left thigh\", \"right thigh\", \"left knee\", \"right knee\", \"left shin\", \"right shin\", \"left calf\",\n",
    "             \"right calf\", \"left ankle\", \"right ankle\", \"left foot\", \"right foot\", \"left toe\", \"right toe\", \"left finger\", \"right finger\", \"left thumb\",\n",
    "             \"right thumb\", \"left hand\", \"right hand\", \"left wrist\", \"right wrist\", \"left forearm\", \"right forearm\", \"left elbow\", \"right elbow\",\n",
    "             \"left upper arm\", \"right upper arm\", \"left shoulder\", \"heart\", \"liver\", \"stomach\", \"intestines\", \"pancreas\", \"spleen\", \"bladder\", \"esophagus\"]\n",
    "\n",
    "len(anatomies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make unique\n",
    "anatomies = list(set(anatomies))\n",
    "len(anatomies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo: Need to combine logic of next two cells to only generate a train_data.csv instead of two files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a random date\n",
    "def generate_example():\n",
    "    output = {}\n",
    "    diagnosis = random.choice(diagnoses['diagnosis'].values)\n",
    "    medication = random.choice(medications['medication'].values)\n",
    "    dosage = random.choice(dosages)\n",
    "    test_name = random.choice(tests['test'].values)\n",
    "    symptom = random.choice(symptoms['symptom'].values)\n",
    "    body_part = random.choice(anatomies)\n",
    "\n",
    "    choices = [diagnosis, medication, dosage, test_name, symptom, body_part]\n",
    "    choice_map = ['diagnosis', 'medication', 'dosage', 'test_name', 'symptom', 'body_part']\n",
    "    entities = []\n",
    "\n",
    "    text_elements = [\n",
    "        f\"The patient was diagnosed with {diagnosis} last year.\",\n",
    "        f\"He has been prescribed {medication} {dosage}.\",\n",
    "        f\"{test_name} measurements indicate {diagnosis}.\",\n",
    "        f\"The {test_name} revealed a {diagnosis} in the {body_part}.\",\n",
    "        f\"Patient presents with {symptom}.\",\n",
    "        f\"Prescribe {dosage} of {medication} for pain relief.\",\n",
    "        f\"The {test_name} shows normal {body_part} function.\",\n",
    "        f\"She mentioned an allergy to {medication}.\",\n",
    "        f\"Examine the {symptom} in the patient's {body_part}.\",\n",
    "    ]\n",
    "    text = random.choice(text_elements)\n",
    "    annotated_segments = []\n",
    "    for index, choice in enumerate(choices):\n",
    "        start_pos = text.find(choice)\n",
    "        if start_pos != -1 and not any(start <= start_pos < end for start, end in annotated_segments):\n",
    "            end_pos = start_pos + len(choice)\n",
    "            entities.append({\"start\": start_pos, \"end\": end_pos, \"label\": choice_map[index]})\n",
    "            annotated_segments.append((start_pos, end_pos))\n",
    "    \n",
    "    output[\"text\"] = text\n",
    "    output[\"entities\"] = entities\n",
    "    return output\n",
    "\n",
    "# Generate 1000 examples\n",
    "train_data = [generate_example() for _ in range(1000)]\n",
    "\n",
    "# Save the examples to a JSON file\n",
    "file_path = '../clean_data/train_data.json'\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(train_data, file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON data\n",
    "with open('../clean_data/train_data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Convert the JSON data to the desired format\n",
    "formatted_data = []\n",
    "for item in data:\n",
    "    text = item['text']\n",
    "    entities = []\n",
    "    for entity in item['entities']:\n",
    "        start = entity['start']\n",
    "        end = entity['end']\n",
    "        label = entity['label']\n",
    "        entities.append((start, end, label.upper()))  # Convert label to uppercase as shown in the example\n",
    "    formatted_data.append((text, {\"entities\": entities}))\n",
    "\n",
    "# Convert to DataFrame for easy CSV saving\n",
    "df = pd.DataFrame(formatted_data, columns=['Text', 'Entities'])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('../clean_data/formatted_train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SYMPTOM', 'MEDICATION', 'TEST_NAME', 'BODY_PART', 'DOSAGE', 'DIAGNOSIS'}\n"
     ]
    }
   ],
   "source": [
    "entity_labels = set()\n",
    "for text, annotations in formatted_data:\n",
    "    for entity in annotations['entities']:\n",
    "        entity_labels.add(entity[2])\n",
    "\n",
    "print(entity_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.8/12.8 MB 23.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in /home/riley/.local/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: jinja2 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (21.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.25.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (59.6.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/riley/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/riley/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.10.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/riley/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/riley/.local/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/riley/.local/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/lib/python3/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.3)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/riley/.local/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/riley/.local/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Diphenoxylate-Atropine 140 ...\" with entities \"[(23, 45, 'MEDICATION'), (46, 51, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed pepcid 170 L.\" with entities \"[(23, 29, 'MEDICATION'), (30, 35, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed orphenadrine 225 g.\" with entities \"[(23, 35, 'MEDICATION'), (36, 41, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed cefuroxime 115 g.\" with entities \"[(23, 33, 'MEDICATION'), (34, 39, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed gentamicin 805 mL.\" with entities \"[(23, 33, 'MEDICATION'), (34, 40, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed mycophenolate 160 mL.\" with entities \"[(23, 36, 'MEDICATION'), (37, 43, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed pradaxa 485 g.\" with entities \"[(23, 30, 'MEDICATION'), (31, 36, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed norethindrone 210 mL.\" with entities \"[(23, 36, 'MEDICATION'), (37, 43, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Zinc oxide 140 L.\" with entities \"[(23, 33, 'MEDICATION'), (34, 39, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed diazepam 730 L.\" with entities \"[(23, 31, 'MEDICATION'), (32, 37, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Xanax 140 L.\" with entities \"[(23, 28, 'MEDICATION'), (29, 34, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed dexamethasone 170 mL.\" with entities \"[(23, 36, 'MEDICATION'), (37, 43, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed lamotrigine 330 g.\" with entities \"[(23, 34, 'MEDICATION'), (35, 40, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Zantac 65 g.\" with entities \"[(23, 29, 'MEDICATION'), (30, 34, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed meloxicam 490 g.\" with entities \"[(23, 32, 'MEDICATION'), (33, 38, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Xarelto 275 g.\" with entities \"[(23, 30, 'MEDICATION'), (31, 36, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Humira 485 g.\" with entities \"[(23, 29, 'MEDICATION'), (30, 35, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed insulin 825 g.\" with entities \"[(23, 30, 'MEDICATION'), (31, 36, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed sulfamethoxazole 270 g.\" with entities \"[(23, 39, 'MEDICATION'), (40, 45, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"SHBG Blood Test measurements indicate Hepatitis A.\" with entities \"[(38, 49, 'DIAGNOSIS'), (0, 15, 'TEST_NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed nabumetone 545 g.\" with entities \"[(23, 33, 'MEDICATION'), (34, 39, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Enulose 885 mL.\" with entities \"[(23, 30, 'MEDICATION'), (31, 37, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"The Total Protein and Albumin/Globulin (A/G) Ratio...\" with entities \"[(63, 96, 'DIAGNOSIS'), (4, 51, 'TEST_NAME'), (104...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Yuvafem 75 mL.\" with entities \"[(23, 30, 'MEDICATION'), (31, 36, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed dexamethasone 375 g.\" with entities \"[(23, 36, 'MEDICATION'), (37, 42, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Jolivette 845 g.\" with entities \"[(23, 32, 'MEDICATION'), (33, 38, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Retin-A 870 g.\" with entities \"[(23, 30, 'MEDICATION'), (31, 36, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed birth control 360 g.\" with entities \"[(23, 36, 'MEDICATION'), (37, 42, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed aspirin 910 g.\" with entities \"[(23, 30, 'MEDICATION'), (31, 36, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed cefuroxime 670 g.\" with entities \"[(23, 33, 'MEDICATION'), (34, 39, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed oxybutynin 495 mL.\" with entities \"[(23, 33, 'MEDICATION'), (34, 40, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed citalopram 260 g.\" with entities \"[(23, 33, 'MEDICATION'), (34, 39, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed hyoscyamine 660 g.\" with entities \"[(23, 34, 'MEDICATION'), (35, 40, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Keflex 645 mL.\" with entities \"[(23, 29, 'MEDICATION'), (30, 36, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed sodium bicarbonate 240 mL.\" with entities \"[(23, 41, 'MEDICATION'), (42, 48, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Vyvanse 160 g.\" with entities \"[(23, 30, 'MEDICATION'), (31, 36, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed ivabradine 325 g.\" with entities \"[(23, 33, 'MEDICATION'), (34, 39, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Patient presents with Renal Cell Cancer Larger Tha...\" with entities \"[(22, 91, 'SYMPTOM')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed sitagliptin 730 g.\" with entities \"[(23, 34, 'MEDICATION'), (35, 40, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed fluconazole 990 L.\" with entities \"[(23, 34, 'MEDICATION'), (35, 40, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed calcium carbonate 105 L.\" with entities \"[(23, 40, 'MEDICATION'), (41, 46, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Humulin 450 g.\" with entities \"[(23, 30, 'MEDICATION'), (31, 36, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Zolpidem 890 g.\" with entities \"[(23, 31, 'MEDICATION'), (32, 37, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed baclofen 485 L.\" with entities \"[(23, 31, 'MEDICATION'), (32, 37, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed naltrexone 175 g.\" with entities \"[(23, 33, 'MEDICATION'), (34, 39, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Remeron 445 L.\" with entities \"[(23, 30, 'MEDICATION'), (31, 36, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Ursodiol 340 L.\" with entities \"[(23, 31, 'MEDICATION'), (32, 37, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed estradiol 455 g.\" with entities \"[(23, 32, 'MEDICATION'), (33, 38, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed albuterol 630 mL.\" with entities \"[(23, 32, 'MEDICATION'), (33, 39, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Benzaclin 160 g.\" with entities \"[(23, 32, 'MEDICATION'), (33, 38, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed tramadol 210 mL.\" with entities \"[(23, 31, 'MEDICATION'), (32, 38, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Namenda 305 mL.\" with entities \"[(23, 30, 'MEDICATION'), (31, 37, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed clopidogrel 795 mL.\" with entities \"[(23, 34, 'MEDICATION'), (35, 41, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Keflex 485 g.\" with entities \"[(23, 29, 'MEDICATION'), (30, 35, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Xifaxan 225 L.\" with entities \"[(23, 30, 'MEDICATION'), (31, 36, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed lasix 730 L.\" with entities \"[(23, 28, 'MEDICATION'), (29, 34, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed ranolazine 430 mL.\" with entities \"[(23, 33, 'MEDICATION'), (34, 40, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed ergocalciferol (vitamin D2)...\" with entities \"[(23, 50, 'MEDICATION'), (51, 57, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed vaginal ointment 870 L.\" with entities \"[(23, 39, 'MEDICATION'), (40, 45, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Enteric 345 L.\" with entities \"[(23, 30, 'MEDICATION'), (31, 36, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Zithromycin 365 mL.\" with entities \"[(23, 34, 'MEDICATION'), (35, 41, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed pyridoxine 170 mL.\" with entities \"[(23, 33, 'MEDICATION'), (34, 40, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Zovirax 440 L.\" with entities \"[(23, 30, 'MEDICATION'), (31, 36, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 1901.4867012440732}\n",
      "Losses {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 802.7633718939912}\n",
      "Losses {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 409.2581662007662}\n",
      "Losses {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 201.94924731371}\n",
      "Losses {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 149.8619921572593}\n",
      "Losses {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 142.1165556747264}\n",
      "Losses {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 129.15740309198557}\n",
      "Losses {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 104.02097749147873}\n",
      "Losses {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 106.88008358253879}\n",
      "Losses {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 75.64500295154807}\n"
     ]
    }
   ],
   "source": [
    "retrain = True # Set to True to retrain the model\n",
    "\n",
    "if os.path.exists('../clean_data/models/ner_model') and not retrain:\n",
    "    nlp = spacy.load('../clean_data/models/ner_model')\n",
    "else:\n",
    "    # Load a blank model\n",
    "    # nlp = spacy.blank('en')\n",
    "\n",
    "    spacy.cli.download(\"en_core_web_sm\")\n",
    "    nlp = spacy.load('en_core_web_sm') # use a pre-trained model\n",
    "\n",
    "    # Add the NER pipeline if not already present\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe('ner')\n",
    "    else:\n",
    "        ner = nlp.get_pipe('ner')\n",
    "\n",
    "    # Add entity labels to the model\n",
    "    for entity in entity_labels:\n",
    "        ner.add_label(entity)\n",
    "\n",
    "    optimizer = nlp.resume_training()\n",
    "    for itn in range(10):  # Number of training iterations\n",
    "        random.shuffle(formatted_data)\n",
    "        losses = {}\n",
    "        for batch in minibatch(formatted_data, size=compounding(4.0, 32.0, 1.001)):\n",
    "            for text, annotations in batch:\n",
    "                doc = nlp.make_doc(text)\n",
    "                example = Example.from_dict(doc, annotations)\n",
    "                nlp.update([example], drop=0.5, sgd=optimizer, losses=losses)\n",
    "        print(\"Losses\", losses)\n",
    "\n",
    "    # Save the model\n",
    "    nlp.to_disk('../clean_data/models/ner_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will need more rigorous testing/improvement im sure, but fine for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500mg DOSAGE\n",
      "Ibuprofen MEDICATION\n"
     ]
    }
   ],
   "source": [
    "# Example text\n",
    "text = \"Patient was administered 500mg of Ibuprofen.\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the predicted entities\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
