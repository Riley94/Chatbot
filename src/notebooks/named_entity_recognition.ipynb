{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import random\n",
    "from spacy.training import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "import io\n",
    "import re\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        medication\n",
      "0    acetaminophen\n",
      "1        acyclovir\n",
      "2         Adderall\n",
      "3        albuterol\n",
      "4      alendronate\n",
      "..             ...\n",
      "375    Zithromycin\n",
      "376         Zoloft\n",
      "377       Zolpidem\n",
      "378        Zovirax\n",
      "379         Zyrtec\n",
      "\n",
      "[380 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# if csv exists, load it\n",
    "if os.path.exists('../../clean_data/medications.csv'):\n",
    "    medications = pd.read_csv('../../clean_data/medications.csv')\n",
    "# otherwise, scrape the data\n",
    "else:\n",
    "    url = \"https://healthy.kaiserpermanente.org/health-wellness/drug-encyclopedia.\"\n",
    "\n",
    "    medications = []\n",
    "\n",
    "    # iterate from 'a' to 'z'\n",
    "    for letter in range(97, 123):\n",
    "        url = url + chr(letter)\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        for li in soup.select(\".drug-column-4\"):\n",
    "            medications.append(li.text)\n",
    "        \n",
    "        url = \"https://healthy.kaiserpermanente.org/health-wellness/drug-encyclopedia.\"\n",
    "\n",
    "    # split by new line\n",
    "    medications = [medication.split('\\n') for medication in medications]\n",
    "    # flatten and remove empty strings\n",
    "    medications = [medication for sublist in medications for medication in sublist if medication != '']\n",
    "    medications = pd.DataFrame(medications, columns=['medication'])\n",
    "    medications.to_csv('../clean_data/medications.csv', index=False)\n",
    "\n",
    "\n",
    "print(medications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "380 medication names to randomize NER data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scope of the application\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "# Function to authenticate and create the service\n",
    "def create_service():\n",
    "    creds = None\n",
    "    # The file token.pickle stores the user's access and refresh tokens.\n",
    "    if os.path.exists('token.pickle'):\n",
    "        with open('token.pickle', 'rb') as token:\n",
    "            creds = pickle.load(token)\n",
    "    # If there are no (valid) credentials available, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for the next run\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(creds, token)\n",
    "    \n",
    "    service = build('drive', 'v3', credentials=creds)\n",
    "    return service\n",
    "\n",
    "# Function to list files in a given folder ID\n",
    "def list_files_in_folder(service, folder_id):\n",
    "    results = service.files().list(q=f\"'{folder_id}' in parents\", fields=\"nextPageToken, files(id, name)\").execute()\n",
    "    items = results.get('files', [])\n",
    "    return items\n",
    "\n",
    "# Function to download a file\n",
    "def download_or_export_file(service, file_id, file_name, mime_type):\n",
    "    try:\n",
    "        # Check if the file is a Google Doc by its MIME type\n",
    "        if mime_type.startswith('application/vnd.google-apps.'):\n",
    "            # Define export MIME type for Google Docs (e.g., 'application/pdf' for Google Docs)\n",
    "            if mime_type == 'application/vnd.google-apps.document':\n",
    "                export_mime_type = 'application/pdf'\n",
    "                file_name += '.pdf'  # Append appropriate file extension\n",
    "            elif mime_type == 'application/vnd.google-apps.spreadsheet':\n",
    "                export_mime_type = 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'\n",
    "                file_name += '.xlsx'  # Append appropriate file extension\n",
    "            elif mime_type == 'application/vnd.google-apps.presentation':\n",
    "                export_mime_type = 'application/vnd.openxmlformats-officedocument.presentationml.presentation'\n",
    "                file_name += '.pptx'  # Append appropriate file extension\n",
    "            else:\n",
    "                # Default to PDF for other Google Apps documents\n",
    "                export_mime_type = 'application/pdf'\n",
    "                file_name += '.pdf'\n",
    "            \n",
    "            request = service.files().export_media(fileId=file_id, mimeType=export_mime_type)\n",
    "        else:\n",
    "            # For binary files, use the get_media method\n",
    "            request = service.files().get_media(fileId=file_id)\n",
    "        \n",
    "        # Perform the download or export\n",
    "        fh = io.BytesIO()\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while not done:\n",
    "            status, done = downloader.next_chunk()\n",
    "            print(f\"Download {int(status.progress() * 100)}%.\")\n",
    "        \n",
    "        # Write the file's contents to a local file\n",
    "        with open(file_name, 'wb') as f:\n",
    "            f.write(fh.getbuffer())\n",
    "        print(f\"File '{file_name}' downloaded successfully.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "def find_folders_by_name(service, folder_name):\n",
    "    \"\"\"Find folders by name and return their IDs.\"\"\"\n",
    "    query = f\"mimeType='application/vnd.google-apps.folder' and name='{folder_name}'\"\n",
    "    response = service.files().list(q=query, spaces='drive', fields='files(id, name)').execute()\n",
    "    return response.get('files', [])\n",
    "\n",
    "def find_subfolder_id(service, parent_folder_id, subfolder_name):\n",
    "    \"\"\"Find a specific subfolder within a parent folder.\"\"\"\n",
    "    query = f\"'{parent_folder_id}' in parents and mimeType='application/vnd.google-apps.folder' and name='{subfolder_name}'\"\n",
    "    response = service.files().list(q=query, spaces='drive', fields='files(id, name)').execute()\n",
    "    files = response.get('files', [])\n",
    "    if files:\n",
    "        return files[0]['id']  # Return the ID of the first matching subfolder\n",
    "    return None\n",
    "\n",
    "def download_txt_files_from_folder(service, folder_id):\n",
    "    \"\"\"Download all .txt files from a specified folder.\"\"\"\n",
    "    query = f\"'{folder_id}' in parents and mimeType='text/plain'\"\n",
    "    response = service.files().list(q=query, spaces='drive', fields='files(id, name, mimeType)').execute()\n",
    "    files = response.get('files', [])\n",
    "    for file in files:\n",
    "        print(f\"Downloading/exporting {file['name']}...\")\n",
    "        download_or_export_file(service, file['id'], file['name'], file['mimeType'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toy diagnosis data. Might look into a better source, but this will work for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 diagnosis\n",
      "0                  Acute Myeloid Leukaemia\n",
      "1     Adrenocortical Carcinoma (Localised)\n",
      "2    Adrenocortical Carcinoma (Metastatic)\n",
      "3      Adrenocortical Carcinoma (Regional)\n",
      "4                             ALL (B Cell)\n",
      "..                                     ...\n",
      "629                           Typhus Fever\n",
      "630                           Valley Fever\n",
      "631                        West Nile Fever\n",
      "632                           Yellow Fever\n",
      "633                             Zika Fever\n",
      "\n",
      "[634 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# again, if csv exists, load it\n",
    "if os.path.exists('../../clean_data/diagnoses.csv'):\n",
    "    diagnoses = pd.read_csv('../../clean_data/diagnoses.csv')\n",
    "# otherwise, download it from Google Drive\n",
    "else:\n",
    "    service = create_service()  # Assume this is implemented as shown before\n",
    "    top_level_folder_names = ['Base-Game', 'Mod-Diagnoses']\n",
    "\n",
    "    for folder_name in top_level_folder_names:\n",
    "        folders = find_folders_by_name(service, folder_name)\n",
    "        for folder in folders:\n",
    "            dept_diagnoses_folder_id = find_subfolder_id(service, folder['id'], 'Dept-Diagnoses')\n",
    "            if dept_diagnoses_folder_id:\n",
    "                download_txt_files_from_folder(service, dept_diagnoses_folder_id)\n",
    "    \n",
    "    diagnoses = []\n",
    "    # loop through all files and extract the text following '##' (diagnosis names)\n",
    "    for file in os.listdir('../../raw_data/diagnoses'):\n",
    "        with open(f'../../raw_data/diagnoses/{file}', 'r') as f:\n",
    "            for line in f:\n",
    "                if '##' in line:\n",
    "                    diagnoses.append(line.split('##')[1].strip())\n",
    "    \n",
    "    diagnoses = pd.DataFrame(diagnoses, columns=['diagnosis']).to_csv('../../clean_data/diagnoses.csv', index=False)\n",
    "\n",
    "print(diagnoses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "634 diagnoses to randomize NER training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some dosages are nonsensical, but will hopefully allow the model to generalize well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['865 g twice daily', '720 L', '95 mL', '545 mg', '595 g', '400 mg every 15 hours', '110 mg', '390 mL', '225 g', '450 g', '40 mL every 1 hours', '105 mL', '90 mL', '375 mL', '735 g', '20 L every 20 hours', '235 mg', '920 mL', '800 g', '310 mg', '965 L every 17 hours', '650 mg', '30 L', '105 mL', '920 mg', '655 mg every 6 hours', '810 g', '345 mL', '505 g', '780 mL', '130 mL every 39 hours', '305 mg', '155 mL', '895 mL', '695 mg', '785 L every 32 hours', '20 mL', '880 g', '55 L', '335 L', '775 L every 23 hours', '725 mL', '475 L', '665 mL', '360 g', '370 mL every 10 hours', '290 g', '265 L', '485 mg', '665 mL', '540 L every 22 hours', '480 L', '780 L', '140 g', '685 g', '500 g every 34 hours', '265 mL', '860 mg', '105 g', '190 mL', '295 L every 7 hours', '295 mg', '385 L', '400 g', '330 mg', '785 L every 18 hours', '280 mg', '85 mg', '265 mg', '125 mg', '995 L every 32 hours', '375 g', '230 L', '30 g', '615 mL', '175 L every 41 hours', '715 L', '235 g', '915 mg', '460 mg', '110 g every 33 hours', '130 L', '755 mL', '90 mg', '975 mg', '655 mg every 22 hours', '60 mg', '290 mL', '665 L', '550 mL', '405 mg every 3 hours', '775 g', '455 L', '565 mL', '480 mg', '645 L every 14 hours', '535 L', '775 L', '740 mL', '690 L', '55 L every 15 hours', '795 L', '960 L', '760 g', '860 mg', '185 mL every 45 hours', '520 mL', '600 g', '75 g', '705 L', '50 L every 9 hours', '515 g', '905 L', '935 g', '325 g', '535 mL every 25 hours', '595 g', '355 L', '305 mL', '670 mg', '450 g every 12 hours', '5 g', '815 mL', '830 g', '865 mL', '720 mL every 31 hours', '425 mg', '200 g', '615 L', '185 L', '75 g every 42 hours', '605 mL', '125 g', '630 mg', '965 g', '760 g every 17 hours', '330 mg', '685 mg', '685 g', '250 mg', '45 g every 8 hours', '860 g', '665 L', '975 L', '940 g', '970 mg every 17 hours', '530 mL', '915 L', '690 g', '205 mL', '150 mL every 9 hours', '570 mg', '310 g', '85 mL', '665 mL', '325 mg every 34 hours', '510 mg', '850 g', '500 mL', '35 g', '60 mL every 46 hours', '810 mL', '795 mg', '800 g', '30 mg', '755 mL every 12 hours', '215 g', '680 g', '235 g', '55 g', '595 mL once daily', '765 mL', '450 L', '410 L', '765 g', '870 mL every 11 hours', '815 L', '815 L', '110 mL', '300 mg', '20 mg every 45 hours', '755 L', '665 mL', '955 g', '290 mg', '200 mL every 30 hours', '920 mL', '540 mL', '275 L', '965 L', '60 L as needed', '310 L', '390 mL', '835 mL', '785 mL', '610 mL every 0 hours', '225 mL', '870 g', '275 L', '715 mg', '240 mg every 40 hours', '715 L', '295 mL', '245 mg', '870 mL', '250 g every 9 hours', '990 mg', '35 mL', '230 L', '755 mL', '780 mg every 35 hours', '435 g', '470 mL', '110 mL', '675 L', '65 mg every 14 hours', '200 g', '850 mg', '1000 g', '845 mg', '20 g every 38 hours', '30 L', '545 mL', '740 g', '165 mg', '505 L every 17 hours', '590 g', '470 L', '85 mL', '220 mg', '395 mL every 33 hours', '850 mg', '245 g', '790 mg', '855 L', '935 mg every 5 hours', '350 mg', '815 mg', '400 mL', '580 mg', '660 mg every 9 hours', '945 mg', '895 g', '305 g', '725 L', '205 mg every 39 hours', '520 L', '195 mg', '660 L', '220 mL', '895 mg every 10 hours', '405 mL', '410 mg', '80 g', '90 L', '585 L every 29 hours', '105 g', '435 g', '720 mg', '515 mL', '965 g every 12 hours', '450 mg', '625 mg', '1000 mL', '265 mL', '610 mL every 35 hours', '290 L', '170 mL', '720 g', '640 mL', '85 mg every 13 hours', '455 g', '160 mg', '550 mL', '850 mL', '235 L every 2 hours', '385 L', '90 L', '520 g', '385 mg', '950 mL every 30 hours', '850 g', '850 L', '130 mg', '740 g', '260 g every 28 hours', '440 mg', '745 g', '130 g', '435 g', '470 L every 45 hours', '435 g', '545 L', '955 mg', '20 mL', '990 mL once daily', '835 L', '645 mL', '305 mL', '50 mg']\n"
     ]
    }
   ],
   "source": [
    "# randomly generate dosage data\n",
    "dosages = []\n",
    "units = ['mg', 'g', 'mL', 'L']\n",
    "concat_every = 5\n",
    "frequency = ['twice daily', 'once daily', 'as needed']\n",
    "\n",
    "for hour in range(48):\n",
    "    frequency.append(f'every {hour} hours')\n",
    "\n",
    "for i in range(300):\n",
    "    dosage = str(random.choice(range(5, 1001, 5))) + f' {random.choice(units)}'\n",
    "    if i % concat_every == 0:\n",
    "        dosage += ' ' + random.choice(frequency)\n",
    "    dosages.append(dosage)\n",
    "\n",
    "print(dosages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if csv exists, load it\n",
    "if os.path.exists('../../clean_data/tests.csv'):\n",
    "    tests = pd.read_csv('../../clean_data/tests.csv')\n",
    "# otherwise, scrape the data\n",
    "else:\n",
    "    url = \"https://medlineplus.gov/lab-tests/\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    tests = []\n",
    "    # select all uorderdered lists with class 'withident breaklist'\n",
    "    for item in soup.select(\".withident.breaklist\"):\n",
    "        tests.append(item.text)\n",
    "\n",
    "    tests = pd.DataFrame(tests, columns=['test'])\n",
    "    tests['test'] = tests['test'].str.split('\\n')\n",
    "    tests = tests.explode('test')\n",
    "    tests = tests[tests['test'] != '']\n",
    "    tests.to_csv('../../clean_data/tests.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if csv exists, load it\n",
    "if os.path.exists('../../clean_data/symptoms.csv'):\n",
    "    symptoms = pd.read_csv('../../clean_data/symptoms.csv')\n",
    "else:\n",
    "    symptoms = []\n",
    "    pattern = r\"\\+\\s(.+?)\\s\\(\\d+% of cases \\| .+?\\)\"\n",
    "\n",
    "    # loop through all files and extract the text following '##' (diagnosis names)\n",
    "    for file in os.listdir('../../raw_data/diagnoses'):\n",
    "        with open(f'../../raw_data/diagnoses/{file}', 'r') as f:\n",
    "            for line in f:\n",
    "                match = re.search(pattern, line)\n",
    "                if match:\n",
    "                    symptoms.append(match.group(1))\n",
    "\n",
    "    symptoms = pd.DataFrame(symptoms, columns=['symptom'])\n",
    "    # make unique\n",
    "    symptoms = symptoms.drop_duplicates()\n",
    "    symptoms.to_csv('../../clean_data/symptoms.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['January 01', 'January 02', 'January 03', 'January 04', 'January 05', 'January 06', 'January 07', 'January 08', 'January 09', 'January 10', 'January 11', 'January 12', 'January 13', 'January 14', 'January 15', 'January 16', 'January 17', 'January 18', 'January 19', 'January 20', 'January 21', 'January 22', 'January 23', 'January 24', 'January 25', 'January 26', 'January 27', 'January 28', 'February 01', 'February 02', 'February 03', 'February 04', 'February 05', 'February 06', 'February 07', 'February 08', 'February 09', 'February 10', 'February 11', 'February 12', 'February 13', 'February 14', 'February 15', 'February 16', 'February 17', 'February 18', 'February 19', 'February 20', 'February 21', 'February 22', 'February 23', 'February 24', 'February 25', 'February 26', 'February 27', 'February 28', 'March 01', 'March 02', 'March 03', 'March 04', 'March 05', 'March 06', 'March 07', 'March 08', 'March 09', 'March 10', 'March 11', 'March 12', 'March 13', 'March 14', 'March 15', 'March 16', 'March 17', 'March 18', 'March 19', 'March 20', 'March 21', 'March 22', 'March 23', 'March 24', 'March 25', 'March 26', 'March 27', 'March 28', 'April 01', 'April 02', 'April 03', 'April 04', 'April 05', 'April 06', 'April 07', 'April 08', 'April 09', 'April 10', 'April 11', 'April 12', 'April 13', 'April 14', 'April 15', 'April 16', 'April 17', 'April 18', 'April 19', 'April 20', 'April 21', 'April 22', 'April 23', 'April 24', 'April 25', 'April 26', 'April 27', 'April 28', 'May 01', 'May 02', 'May 03', 'May 04', 'May 05', 'May 06', 'May 07', 'May 08', 'May 09', 'May 10', 'May 11', 'May 12', 'May 13', 'May 14', 'May 15', 'May 16', 'May 17', 'May 18', 'May 19', 'May 20', 'May 21', 'May 22', 'May 23', 'May 24', 'May 25', 'May 26', 'May 27', 'May 28', 'June 01', 'June 02', 'June 03', 'June 04', 'June 05', 'June 06', 'June 07', 'June 08', 'June 09', 'June 10', 'June 11', 'June 12', 'June 13', 'June 14', 'June 15', 'June 16', 'June 17', 'June 18', 'June 19', 'June 20', 'June 21', 'June 22', 'June 23', 'June 24', 'June 25', 'June 26', 'June 27', 'June 28', 'July 01', 'July 02', 'July 03', 'July 04', 'July 05', 'July 06', 'July 07', 'July 08', 'July 09', 'July 10', 'July 11', 'July 12', 'July 13', 'July 14', 'July 15', 'July 16', 'July 17', 'July 18', 'July 19', 'July 20', 'July 21', 'July 22', 'July 23', 'July 24', 'July 25', 'July 26', 'July 27', 'July 28', 'August 01', 'August 02', 'August 03', 'August 04', 'August 05', 'August 06', 'August 07', 'August 08', 'August 09', 'August 10', 'August 11', 'August 12', 'August 13', 'August 14', 'August 15', 'August 16', 'August 17', 'August 18', 'August 19', 'August 20', 'August 21', 'August 22', 'August 23', 'August 24', 'August 25', 'August 26', 'August 27', 'August 28', 'September 01', 'September 02', 'September 03', 'September 04', 'September 05', 'September 06', 'September 07', 'September 08', 'September 09', 'September 10', 'September 11', 'September 12', 'September 13', 'September 14', 'September 15', 'September 16', 'September 17', 'September 18', 'September 19', 'September 20', 'September 21', 'September 22', 'September 23', 'September 24', 'September 25', 'September 26', 'September 27', 'September 28', 'October 01', 'October 02', 'October 03', 'October 04', 'October 05', 'October 06', 'October 07', 'October 08', 'October 09', 'October 10', 'October 11', 'October 12', 'October 13', 'October 14', 'October 15', 'October 16', 'October 17', 'October 18', 'October 19', 'October 20', 'October 21', 'October 22', 'October 23', 'October 24', 'October 25', 'October 26', 'October 27', 'October 28', 'November 01', 'November 02', 'November 03', 'November 04', 'November 05', 'November 06', 'November 07', 'November 08', 'November 09', 'November 10', 'November 11', 'November 12', 'November 13', 'November 14', 'November 15', 'November 16', 'November 17', 'November 18', 'November 19', 'November 20', 'November 21', 'November 22', 'November 23', 'November 24', 'November 25', 'November 26', 'November 27', 'November 28', 'December 01', 'December 02', 'December 03', 'December 04', 'December 05', 'December 06', 'December 07', 'December 08', 'December 09', 'December 10', 'December 11', 'December 12', 'December 13', 'December 14', 'December 15', 'December 16', 'December 17', 'December 18', 'December 19', 'December 20', 'December 21', 'December 22', 'December 23', 'December 24', 'December 25', 'December 26', 'December 27', 'December 28']\n"
     ]
    }
   ],
   "source": [
    "dates = []\n",
    "\n",
    "# generate dates in the format \"Month Day\"\n",
    "for i in range(1, 13):\n",
    "    for j in range(1, 29):\n",
    "        # year is arbitrary\n",
    "        date = datetime.date(2021, i, j)\n",
    "        full_date = f\"{date.strftime('%B')} {date.strftime('%d')}\"\n",
    "        dates.append(full_date)\n",
    "\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "# generate times in the format \"Hour AM/PM\"\n",
    "for i in range(1, 13):\n",
    "    for j in [\"AM\", \"PM\"]:\n",
    "        time = f\"{i} {j}\"\n",
    "        times.append(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Body parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard-coding for now. Will change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anatomies = [\"left femur\", \"right knee\", \"abdominal region\", \"left lung\", \"right lung\", \"left kidney\", \"right kidney\",\n",
    "             \"left eye\", \"right eye\", \"left ear\", \"right ear\", \"left hand\", \"right hand\", \"left foot\", \"right foot\",\n",
    "             \"left arm\", \"right arm\", \"left leg\", \"right leg\", \"left shoulder\", \"right shoulder\", \"left hip\", \"right hip\",\n",
    "             \"left elbow\", \"right elbow\", \"left wrist\", \"right wrist\", \"left ankle\", \"right ankle\", \"left toe\", \"right toe\",\n",
    "             \"left finger\", \"right finger\", \"left thumb\", \"right thumb\", \"left nostril\", \"right nostril\", \"left cheek\", \"right cheek\",\n",
    "             \"left temple\", \"right temple\", \"left jaw\", \"right jaw\", \"left chin\", \"right chin\", \"left neck\", \"right neck\", \"left collarbone\",\n",
    "             \"right collarbone\", \"left rib\", \"right rib\", \"left hip bone\", \"right hip bone\", \"left thigh\", \"right thigh\", \"left calf\",\n",
    "             \"right calf\", \"left shin\", \"right shin\", \"left heel\", \"right heel\", \"left sole\", \"right sole\", \"left toe\", \"right toe\",\n",
    "             \"left finger\", \"right finger\", \"left thumb\", \"right thumb\", \"left palm\", \"right palm\", \"left wrist\", \"right wrist\", \"left forearm\",\n",
    "             \"right forearm\", \"left bicep\", \"right bicep\", \"left tricep\", \"right tricep\", \"left shoulder\", \"right shoulder\", \"left chest\", \"right chest\",\n",
    "             \"left breast\", \"right breast\", \"left nipple\", \"right nipple\", \"left rib\", \"right rib\", \"left abdomen\", \"right abdomen\", \"left hip\",\n",
    "             \"right hip\", \"left groin\", \"right groin\", \"left thigh\", \"right thigh\", \"left knee\", \"right knee\", \"left shin\", \"right shin\", \"left calf\",\n",
    "             \"right calf\", \"left ankle\", \"right ankle\", \"left foot\", \"right foot\", \"left toe\", \"right toe\", \"left finger\", \"right finger\", \"left thumb\",\n",
    "             \"right thumb\", \"left hand\", \"right hand\", \"left wrist\", \"right wrist\", \"left forearm\", \"right forearm\", \"left elbow\", \"right elbow\",\n",
    "             \"left upper arm\", \"right upper arm\", \"left shoulder\", \"heart\", \"liver\", \"stomach\", \"intestines\", \"pancreas\", \"spleen\", \"bladder\", \"esophagus\"]\n",
    "\n",
    "len(anatomies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make unique\n",
    "anatomies = list(set(anatomies))\n",
    "len(anatomies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo: Need to combine logic of next two cells to only generate a train_data.csv instead of two files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a random date\n",
    "def generate_example():\n",
    "    output = {}\n",
    "    diagnosis = random.choice(diagnoses['diagnosis'].values)\n",
    "    medication = random.choice(medications['medication'].values)\n",
    "    dosage = random.choice(dosages)\n",
    "    test_name = random.choice(tests['test'].values)\n",
    "    symptom = random.choice(symptoms['symptom'].values)\n",
    "    body_part = random.choice(anatomies)\n",
    "\n",
    "    choices = [diagnosis, medication, dosage, test_name, symptom, body_part]\n",
    "    choice_map = ['diagnosis', 'medication', 'dosage', 'test_name', 'symptom', 'body_part']\n",
    "    entities = []\n",
    "\n",
    "    text_elements = [\n",
    "        f\"The patient was diagnosed with {diagnosis} last year.\",\n",
    "        f\"He has been prescribed {medication} {dosage}.\",\n",
    "        f\"{test_name} measurements indicate {diagnosis}.\",\n",
    "        f\"The {test_name} revealed a {diagnosis} in the {body_part}.\",\n",
    "        f\"Patient presents with {symptom}.\",\n",
    "        f\"Prescribe {dosage} of {medication} for pain relief.\",\n",
    "        f\"The {test_name} shows normal {body_part} function.\",\n",
    "        f\"She mentioned an allergy to {medication}.\",\n",
    "        f\"Examine the {symptom} in the patient's {body_part}.\",\n",
    "    ]\n",
    "    text = random.choice(text_elements)\n",
    "    for index, choice in enumerate(choices):\n",
    "        if text.find(choice) != -1:\n",
    "            entities.append({\"start\": text.find(choice), \"end\": text.find(choice) + len(choice), \"label\": f\"{choice_map[index]}\"})\n",
    "    \n",
    "    output[\"text\"] = text\n",
    "    output[\"entities\"] = entities\n",
    "    return output\n",
    "\n",
    "# Generate 1000 examples\n",
    "train_data = [generate_example() for _ in range(1000)]\n",
    "\n",
    "# Save the examples to a JSON file\n",
    "file_path = '../../clean_data/train_data.json'\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(train_data, file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON data\n",
    "with open('../../clean_data/train_data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Convert the JSON data to the desired format\n",
    "formatted_data = []\n",
    "for item in data:\n",
    "    text = item['text']\n",
    "    entities = []\n",
    "    for entity in item['entities']:\n",
    "        start = entity['start']\n",
    "        end = entity['end']\n",
    "        label = entity['label']\n",
    "        entities.append((start, end, label.upper()))  # Convert label to uppercase as shown in the example\n",
    "    formatted_data.append((text, {\"entities\": entities}))\n",
    "\n",
    "# Convert to DataFrame for easy CSV saving\n",
    "df = pd.DataFrame(formatted_data, columns=['Text', 'Entities'])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('../../clean_data/formatted_train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TEST_NAME', 'BODY_PART', 'MEDICATION', 'SYMPTOM', 'DOSAGE', 'DIAGNOSIS'}\n"
     ]
    }
   ],
   "source": [
    "entity_labels = set()\n",
    "for text, annotations in formatted_data:\n",
    "    for entity in annotations['entities']:\n",
    "        entity_labels.add(entity[2])\n",
    "\n",
    "print(entity_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.8/12.8 MB 21.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in /home/riley/.local/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (59.6.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: jinja2 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.25.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/riley/.local/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/riley/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/riley/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/riley/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.10.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/riley/.local/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/riley/.local/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/lib/python3/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.3)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/riley/.local/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/riley/.local/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Lamictal 755 mL.\" with entities \"[(23, 31, 'MEDICATION'), (32, 38, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed diazepam 450 L.\" with entities \"[(23, 31, 'MEDICATION'), (32, 37, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed tramadol 360 g.\" with entities \"[(23, 31, 'MEDICATION'), (32, 37, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Bayer Aspirin 815 L.\" with entities \"[(23, 36, 'MEDICATION'), (37, 42, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed salicylic acid 860 g.\" with entities \"[(23, 37, 'MEDICATION'), (38, 43, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed fenofibrate 940 g.\" with entities \"[(23, 34, 'MEDICATION'), (35, 40, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Prenatal Vitamins 860 g.\" with entities \"[(23, 40, 'MEDICATION'), (41, 46, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed cefuroxime 940 g.\" with entities \"[(23, 33, 'MEDICATION'), (34, 39, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Imdur 515 g.\" with entities \"[(23, 28, 'MEDICATION'), (29, 34, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed DOK 100 205 mL.\" with entities \"[(23, 30, 'MEDICATION'), (31, 37, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed isotretinoin 810 mL.\" with entities \"[(23, 35, 'MEDICATION'), (36, 42, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed HySept 965 g.\" with entities \"[(23, 29, 'MEDICATION'), (30, 35, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Bayer Aspirin 615 L.\" with entities \"[(23, 36, 'MEDICATION'), (37, 42, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"The Total Protein and Albumin/Globulin (A/G) Ratio...\" with entities \"[(4, 51, 'TEST_NAME'), (65, 76, 'BODY_PART')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Norvasc 665 mL.\" with entities \"[(23, 30, 'MEDICATION'), (31, 37, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Patient presents with An Enlarged Prostate Gland T...\" with entities \"[(22, 78, 'SYMPTOM')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Hearing Tests for Adults measurements indicate Hep...\" with entities \"[(47, 58, 'DIAGNOSIS'), (0, 24, 'TEST_NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed baclofen 170 mL.\" with entities \"[(23, 31, 'MEDICATION'), (32, 38, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed tramadol 940 g.\" with entities \"[(23, 31, 'MEDICATION'), (32, 37, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed epinephrine 55 L.\" with entities \"[(23, 34, 'MEDICATION'), (35, 39, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed fluticasone 105 mL.\" with entities \"[(23, 34, 'MEDICATION'), (35, 41, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed silodosin 130 g.\" with entities \"[(23, 32, 'MEDICATION'), (33, 38, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed pantoprazole 500 mL.\" with entities \"[(23, 35, 'MEDICATION'), (36, 42, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Breo Ellipta 230 L.\" with entities \"[(23, 35, 'MEDICATION'), (36, 41, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed methylprednisolone 665 mL.\" with entities \"[(23, 41, 'MEDICATION'), (42, 48, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed glimepiride 755 mL.\" with entities \"[(23, 34, 'MEDICATION'), (35, 41, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed rizatriptan 310 L.\" with entities \"[(23, 34, 'MEDICATION'), (35, 40, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Keflex 960 L.\" with entities \"[(23, 29, 'MEDICATION'), (30, 35, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed nifedipine 275 L.\" with entities \"[(23, 33, 'MEDICATION'), (34, 39, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Nephro-Vite 735 g.\" with entities \"[(23, 34, 'MEDICATION'), (35, 40, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed terazosin 815 L.\" with entities \"[(23, 32, 'MEDICATION'), (33, 38, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed ketoconazole 715 L.\" with entities \"[(23, 35, 'MEDICATION'), (36, 41, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Remeron 30 g.\" with entities \"[(23, 30, 'MEDICATION'), (31, 35, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed peg 3350 835 mL.\" with entities \"[(23, 31, 'MEDICATION'), (32, 38, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Humira 960 L.\" with entities \"[(23, 29, 'MEDICATION'), (30, 35, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed fluticasone 140 g.\" with entities \"[(23, 34, 'MEDICATION'), (35, 40, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Chantix 785 mL.\" with entities \"[(23, 30, 'MEDICATION'), (31, 37, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed sertraline 550 mL.\" with entities \"[(23, 33, 'MEDICATION'), (34, 40, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed bisacodyl 55 L.\" with entities \"[(23, 32, 'MEDICATION'), (33, 37, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Yuvafem 185 L.\" with entities \"[(23, 30, 'MEDICATION'), (31, 36, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed imiquimod 450 L.\" with entities \"[(23, 32, 'MEDICATION'), (33, 38, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed metronidazole 725 L.\" with entities \"[(23, 36, 'MEDICATION'), (37, 42, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Seroquel 20 mL.\" with entities \"[(23, 31, 'MEDICATION'), (32, 37, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Ventolin 390 mL.\" with entities \"[(23, 31, 'MEDICATION'), (32, 38, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Mobic 275 L.\" with entities \"[(23, 28, 'MEDICATION'), (29, 34, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed OneTouch 435 g.\" with entities \"[(23, 31, 'MEDICATION'), (32, 37, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed viagra 245 g.\" with entities \"[(23, 29, 'MEDICATION'), (30, 35, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed viagra 870 mL.\" with entities \"[(23, 29, 'MEDICATION'), (30, 36, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed diltiazem 290 L.\" with entities \"[(23, 32, 'MEDICATION'), (33, 38, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Prenatal Vitamins 905 L.\" with entities \"[(23, 40, 'MEDICATION'), (41, 46, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed fluticasone 470 mL.\" with entities \"[(23, 34, 'MEDICATION'), (35, 41, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Imdur 855 L.\" with entities \"[(23, 28, 'MEDICATION'), (29, 34, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed HySept 235 g.\" with entities \"[(23, 29, 'MEDICATION'), (30, 35, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed methotrexate 290 g.\" with entities \"[(23, 35, 'MEDICATION'), (36, 41, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed glipizide 725 L.\" with entities \"[(23, 32, 'MEDICATION'), (33, 38, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed omeprazole 450 L.\" with entities \"[(23, 33, 'MEDICATION'), (34, 39, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed fenofibrate 725 mL.\" with entities \"[(23, 34, 'MEDICATION'), (35, 41, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed triamcinolone 360 g.\" with entities \"[(23, 36, 'MEDICATION'), (37, 42, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"The Total Protein and Albumin/Globulin (A/G) Ratio...\" with entities \"[(4, 51, 'TEST_NAME'), (65, 79, 'BODY_PART')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed bisacodyl 735 g.\" with entities \"[(23, 32, 'MEDICATION'), (33, 38, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed olanzapine 225 mL.\" with entities \"[(23, 33, 'MEDICATION'), (34, 40, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed doxycycline 275 L.\" with entities \"[(23, 34, 'MEDICATION'), (35, 40, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed HySept 660 L.\" with entities \"[(23, 29, 'MEDICATION'), (30, 35, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Augmentin 920 mL.\" with entities \"[(23, 32, 'MEDICATION'), (33, 39, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed brompheniramine 715 L.\" with entities \"[(23, 38, 'MEDICATION'), (39, 44, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed montelukast 275 L.\" with entities \"[(23, 34, 'MEDICATION'), (35, 40, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed aripiprazole 30 L.\" with entities \"[(23, 35, 'MEDICATION'), (36, 40, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Urea 720 L.\" with entities \"[(23, 27, 'MEDICATION'), (28, 33, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed levothyroxine 90 mL.\" with entities \"[(23, 36, 'MEDICATION'), (37, 42, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Virtussin 640 mL.\" with entities \"[(23, 32, 'MEDICATION'), (33, 39, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Kidney Stone Analysis measurements indicate Clear ...\" with entities \"[(44, 84, 'DIAGNOSIS'), (0, 21, 'TEST_NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Hydromet 90 mL.\" with entities \"[(23, 31, 'MEDICATION'), (32, 37, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Jardiance 35 g.\" with entities \"[(23, 32, 'MEDICATION'), (33, 37, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed fluticasone 895 mL.\" with entities \"[(23, 34, 'MEDICATION'), (35, 41, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Lyrica 375 mL.\" with entities \"[(23, 29, 'MEDICATION'), (30, 36, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed phentermine 965 L.\" with entities \"[(23, 34, 'MEDICATION'), (35, 40, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Zantac 870 mL.\" with entities \"[(23, 29, 'MEDICATION'), (30, 36, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed vaginal cream 665 mL.\" with entities \"[(23, 36, 'MEDICATION'), (37, 43, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed fluconazole 265 mL.\" with entities \"[(23, 34, 'MEDICATION'), (35, 41, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed hydrocodone 720 L.\" with entities \"[(23, 34, 'MEDICATION'), (35, 40, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed hyoscyamine 660 L.\" with entities \"[(23, 34, 'MEDICATION'), (35, 40, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed diosmin 785 mL.\" with entities \"[(23, 30, 'MEDICATION'), (31, 37, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Remeron 740 g.\" with entities \"[(23, 30, 'MEDICATION'), (31, 36, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed budesonide 470 L.\" with entities \"[(23, 33, 'MEDICATION'), (34, 39, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed furosemide 735 g.\" with entities \"[(23, 33, 'MEDICATION'), (34, 39, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Generlac 940 g.\" with entities \"[(23, 31, 'MEDICATION'), (32, 37, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/riley/.local/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"He has been prescribed Benadryl 665 mL.\" with entities \"[(23, 31, 'MEDICATION'), (32, 38, 'DOSAGE')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 2055.0547043412544}\n",
      "Losses {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 832.7350446841641}\n",
      "Losses {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 394.5145583335001}\n",
      "Losses {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 260.49499817842656}\n",
      "Losses {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 173.4652899405811}\n",
      "Losses {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 147.779243923613}\n",
      "Losses {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 90.77088567459491}\n",
      "Losses {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 93.06171735056289}\n",
      "Losses {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 82.61153124124401}\n",
      "Losses {'tok2vec': 0.0, 'tagger': 0.0, 'parser': 0.0, 'ner': 162.6401452881953}\n"
     ]
    }
   ],
   "source": [
    "retrain = True # Set to True to retrain the model\n",
    "\n",
    "if os.path.exists('../../clean_data/models/ner_model') and not retrain:\n",
    "    nlp = spacy.load('../../clean_data/models/ner_model')\n",
    "else:\n",
    "    # Load a blank model\n",
    "    # nlp = spacy.blank('en')\n",
    "\n",
    "    spacy.cli.download(\"en_core_web_sm\")\n",
    "    nlp = spacy.load('en_core_web_sm') # use a pre-trained model\n",
    "\n",
    "    # Add the NER pipeline if not already present\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe('ner')\n",
    "    else:\n",
    "        ner = nlp.get_pipe('ner')\n",
    "\n",
    "    # Add entity labels to the model\n",
    "    for entity in entity_labels:\n",
    "        ner.add_label(entity)\n",
    "\n",
    "    optimizer = nlp.resume_training()\n",
    "    for itn in range(10):  # Number of training iterations\n",
    "        random.shuffle(formatted_data)\n",
    "        losses = {}\n",
    "        for batch in minibatch(formatted_data, size=compounding(4.0, 32.0, 1.001)):\n",
    "            for text, annotations in batch:\n",
    "                doc = nlp.make_doc(text)\n",
    "                example = Example.from_dict(doc, annotations)\n",
    "                nlp.update([example], drop=0.5, sgd=optimizer, losses=losses)\n",
    "        print(\"Losses\", losses)\n",
    "\n",
    "    # Save the model\n",
    "    nlp.to_disk('../../clean_data/models/ner_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will need more rigorous testing/improvement im sure, but fine for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500mg DOSAGE\n",
      "Ibuprofen MEDICATION\n"
     ]
    }
   ],
   "source": [
    "# Example text\n",
    "text = \"Patient was administered 500mg of Ibuprofen.\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the predicted entities\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
